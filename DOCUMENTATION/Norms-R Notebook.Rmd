---
title: "Creating age-stratified norms in R"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

<br>

#### HOW TO USE THIS DOCUMENT:
This R Notebook (.rmd) contains chunks of runnable code along with detailed analysis and documentation of the code and workflow. To use this Notebook, render (knit) it as an HTML document into the RStudio Viewer Pane:

1. In RStudio Preferences, R Markdown section, set the `Show output preview in:` option to `Viewer Pane`.
2. Knit the notebook using `File -> Knit Document`. This will produce a readable HTML version of this document in the Viewer Pane. 
3. Close this Notebook (once you have the HTML in the Viewer, you no longer need the Notebook).
4. Open a new R script in the Source Pane. This will serve as your working script, into which you can copy-and-paste code from the HTML.

The HTML narrative is organized into sections reflecting discrete topics and operations in the R workflow. Each section has two parts:

1. `VALID CODE TO RUN`: this code can be copy-and-pasted into your working R script. Before running, make sure that all file paths relating to input and output files are specified correctly for your local environment. __Note that all code in this Notebook was written for the Mac OS, so if you are working in Windows, you may need to substitute `\` for `/` in file paths.__
2. `COMMENTED CODE CHUNKS`: these snippets provide the analysis and documentation of the code and workflow. The R code in these snippets is redundant with that in `VALID CODE TO RUN` section. Here, it serves merely to enhance the code documenatation, and is not meant to be run.

<br>

#### CREATE AN RStudio PROJECT WITH STANDARD FOLDER STRUCTURE:
To keep your work organized, set up a project in RStudio, by clicking File -> New Project. You'll be asked to specify a working directory associated with the project. Create the following folders within the working directory:

* `CODE`
* `INPUT-FILES`
* `OUTPUT-FILES`
    + `DESCRIPTIVE-TABLES`
    + `FINAL-RAW-TO-SS-LOOKUP-TABLES`

As mentioned above, you need to make sure file paths in your script are specified correctly, in order to read input files and/or write output files.

<br>

#### STARTING INPUT:
The norming script requires two types of starting input: *data* and *parameters*.

##### Input Data File 
This file is a sample of cases with the raw score to be normed. It is required, and must be located in the `INPUT-FILES` folder, with the following specifications:

* __.csv__ format
* Must have at least these **numeric** variables (columns): 
     + `ID`: (exact spelling/capitalization)
     + `agestrat`: (exact spelling/capitalization)
     + name of raw score to be normed
* `agestrat` coding: values are number of months equivalent to lower bound of each agestrat. Examples of coding:
     + 0 months - 2 months = 0
     + 03:05 = 3
     + 1-2 years = 12
     + 7-6 to 8-0 = 90
     + 18-21 years = 216
     
##### Input Parameters
The script allows you to enter the input parameters interactively at the console, or retrieve them from a saved file. The latter method is preferred because it reduces keyboard entry when running the script numerous times. The input parameters file must be located in the `INPUT-FILES` folder, with the following specifications:

* Exact file name: `Input-Parameters.R`
* Saved as an R script: copy code below into script and insert names/values where indicated (preserving quote marks where applicable)

```{r input_parameters, eval=FALSE}
input_file_name <- c('insert file name here')
score_name <- c('insert score name here')
max_raw <- insert maximum raw score value here
min_raw <- insert minimum raw score value here
```


<br>

#### PACKAGES

To use the code in this Notebook, install these packages and load them using `library()`:

* `here`: Robust method for specifying file paths
* `reshape2`: Collapse columns to rows, vice versa
* `moderndive`: User-friendly linear modeling, regression and correlation tools
* `magrittr`: Pipe operators
* `tidyverse`: Many essential packages for data wrangling, analysis (`tidyr`, `dplyr`, `purrr`, `ggplot2`, `readr`, etc.)
* `ggpmisc`: Add equations, fit statistics to line plots
* `ggrepel`: more `ggplot2` extensions

In this Notebook, the double-colon `::` notation is used to identify a function's source package (e.g., `base::eval()`, `dplyr::select()`, etc.)

###### VALID CODE TO RUN
```{r packages, message=FALSE}
suppressMessages(library(here))
library(reshape2)
suppressMessages(library(moderndive))
library(magrittr)
suppressMessages(suppressWarnings(library(tidyverse)))
suppressMessages(library(ggpmisc))
library(ggrepel)
```
Note use of `base::suppressMessages()` to silence chatter during startup; and use of `base::suppressWarnings()` to silence chatter during interactive session.

<br>

#### CODE OVERVIEW
This script takes as input a table containing cases of a raw score to be normed. It is assumed that the score has an age-related developmental progression, and requires ages-stratified norms. The input table is transformed through the following stages of the norming process:

* Read in and examine data: raw score descriptive statistics, histograms, plots
* Select cumulative percentage points to normalize the raw score distribution within each age group (`agestrat`)
* Impute normalized medians by `agestrat`, split SD into `lo` and `hi` components
* Use linear modeling to smooth medians, lo SDs, and hi SDs
* Impute new age groups to compensate for larger-than-expected raw score changes between adjacent groups (optional)
* Adjust smoothed medians, SDs by hand to correct score reversals, compensate for floor/ceiling effects (optional)
* Generate publication-ready raw-to-standard-score lookup tables

<br>

#### Select method for entering input parameters; read input dataa

###### VALID CODE TO RUN
```{r input, eval=FALSE}
input_parameters_prompt <- function() {
  writeLines(
    "To initiate the norming process, R requires certain input parameters. Please choose a method for entering these parameters:\n\n1: Interactively at the console\n2: From a file named 'Input-Parameters.R' located in '[PROJECT DIRECTORY]/INPUT-FILES'\n"
  )
  input_choice <- as.numeric(0)
  while (is.na(input_choice) || (!(input_choice %in% 1:2))) {
    input_choice <-
      suppressWarnings(as.numeric(readline(prompt = "Enter choice: ")))
    if (is.na(input_choice)) {
      writeLines("Please enter 1 or 2\n")
    } else {
      if (input_choice == 1) {
        cat("Enter the name of the input file, including the .csv suffix.\nUse exact spelling and capitalization.")
        suppressWarnings(as.character(
          readline(prompt = "Input file: ")
        )) %>% assign('input_file_name', ., envir = .GlobalEnv)
        cat("\nEnter the column name of the score to be normed.\nUse exact spelling and capitalization.")
        suppressWarnings(as.character(
          readline(prompt = "Score name: ")
        )) %>% assign('score_name', ., envir = .GlobalEnv)
        cat("\nEnter the HIGHEST possible raw score for the score to be normed.")
        suppressWarnings(as.integer(
          readline(prompt = "Maximum raw score: ")
        )) %>% assign('max_raw', ., envir = .GlobalEnv)
        cat("\nEnter the LOWEST possible raw score for the score to be normed.")
        suppressWarnings(as.integer(
          readline(prompt = "Minimum raw score: ")
        )) %>% assign('min_raw', ., envir = .GlobalEnv)
        break
      } else if (input_choice == 2) {
        source(here('INPUT-FILES/Input-Parameters.R'))
        break
      } else {
        writeLines("Please enter 1 or 2\n")
      }
    }
  }
}
input_parameters_prompt()

suppressMessages(
  read_csv(
    here(
      paste0('INPUT-FILES/', input_file_name)
    )
  )
) %>% 
  group_by(agestrat) %>% 
  assign(paste0(score_name, '_raw_by_agestrat'), ., envir = .GlobalEnv)
num_agestrat <- length(unique(eval(as.name(paste0(score_name, '_raw_by_agestrat')))$agestrat))
```
###### COMMENTED CODE CHUNKS
The script begins with an interactive session, where the user is prompted at the console to choose a method for entering input parameters. This interactive session can only be executed from source by entering `command-shift-S`. The code won't function properly if run as an isolated block using `command-enter`; this mode of execution wonâ€™t pause and wait for user input.

`base::function()` creates a function to run this interactive session. The function is assigned `<-` the name `input_parameters_prompt`. `base::writeLines` prints a numbered list of user instructions to the console, using the escape character `\n` to insert line breaks in the displayed text. The user can choose to enter input parameters interactively at the console, or load them from a file located in a specifc directory in the R project folder structure.
```{r input, echo=1:4, eval=FALSE}
```

`input_choice` is initialized as a numeric vector with placeholder value of 0. Within the function `input_parameters_prompt`, `input_choice` will hold the numerical value that the user enters when prompted by the console instructions. The value of `input_choice` controls the flow of logic within `input_parameters_prompt`; its value determines which input parameter entry method will be utilized. 

Note that the assignment operator `<-` is used to initialize `input_choice`, rather than the `base::assign()` function that is used elsewhere inside script-defined functions. The reason for this is that `input_choice` is a temporary variable that is not utilized outside of the body of this particular function. Thus, it does not need to be made available in the global environment. When `<-` is used within the body of a function, the object thereby created is avaiable only in the local environment of that function. In this instance, we can get away with using `<-` because `input_choice` is not needed in the global environment.
```{r input, echo=5, eval=FALSE}
```
The code for input parameter entry method is called and executed within a `while` loop, which iterates as long as a compound logical condition is met (logical "or" `||`). This condition is specified by `is.na(input_choice) || (!(input_choice %in% 1:2)`, which tells the `while` loop to keep iterating as long as the value of `model_choice` is anything other than 1 or 2 (i.e., the user enters a non-permitted value at the console). Thus, if the user enters an integer other than 1 or 2, or any other keystroke(s), including `enter` without an entry, the loop will continue to iterate and control will _not_ be passed to downstream code. `is.na(model_choice)` is included in this compound condition because any keystroke other than 1 or 2 is coerced to `NA` (R code for missing) within this function. Thus, the loop keeps iterating if the function returns `NA`.
```{r input, echo=6, eval=FALSE}
```
Within the `while` loop, `input_choice` is respecified to read user input from the console. `base::readline()` allows the specification of a prompt at the console, and reads user keystroke input, which is then assigned to `input_choice`. Wrapping `readline` in `suppressWarnings` keeps the displayed text on the console clean and readable.
```{r input, echo=7:8, eval=FALSE}
```
`if`-`else` statements control the flow of operations within the loop. The first `if` statement specifies that if `input_choice` is `NA` (i.e., the user enters a non-permitted keystroke(s) at the console), `writeLines` prints a reminder to enter a permitted keystroke, and then control returns to the beginning of the loop, where `readline` again prompts the user to enter a model choice.
```{r input, echo=9:10, eval=FALSE}
```
Next comes a nested logical flow that is subsumed under `else`. When control enters the nested flow, the logical condition is that `input_choice` is _not_ `NA`. The nested `if`-`else` statements control what happens when the user enters a permitted choice (i.e., the value of `input_choice` is 1 or 2). Under the first of these conditions (specified by `if (input_choice == 1)`), the user is prompted to enter the four input parameters (`input_file_name`, `score_name`, `max_raw`, `min_raw`) at the console. The instructions for entry are printed to the screen by callling `base::cat()`, which converts its arguments to character vectors and displays them on the screen. `readline()` is used to capture user input, which is then sent to `assign()` using the pipe operator `%>%`. `assign` names the input object and makes it available in the global environment for downstream code.

Under the second condition (defined by `else if (input_choice == 2)`), the input parameters are read in from a preconfigured R script (`Input-Parameters.R`, created with instructions given earlier in this Notebook). `base::source()` is used to execute this script, from the location given by `here('INPUT-FILES/Input-Parameters.R')`, which provides a directory path from the R project folder.

The `if` and `else if` conditions are followed by `break` which causes control to exit the loop and continue into downstream code. Thus, the `input_parameters_prompt` function prompts the user to select a method of input parameter entry, repeats the prompt when a non-permitted keystroke is entered, and ultimately executes one of two entry methods and makes the output of the selected method available to downstream code.
```{r input, echo=11:32, eval=FALSE}
```
A final `else` condition is triggered by any user input not subsumed under the prior logical conditions. It reprompts the user, and returns control to the beginning of the loop. As noted above, the loop will only stop running if the user enters 1 or 2.
```{r input, echo=33:34, eval=FALSE}
```
`input_parameters_prompt` is called with empty parentheses `()` because it takes no arguments. The function simply executes the code within its body, it does not depend on any input values specified in the function call.
```{r input, echo=39, eval=FALSE}
```
The next snippet reads the input date file (normative sample) using `readr::read_csv`. The file path within `here::here()` is concatenated with `paste0()`, which joins a static string with the character vector `input_file_name`, an input parameter initialized by upstream code.
```{r input, echo=41:47, eval=FALSE}
```
The input data file is piped forward into `dplyr::group_by`, which groups the rows according to their values on `agestrat` (the grouping will be utilized by downstream processes). The data file is then saved as an object in the global environment using `assign()`. Within the `assign` call, the first argument is the object name, which is a string concatenated by `paste0()`, joining the input parameter `score_name` with a static suffix `_raw_by_agestrat`. The second argument of `assign` is the piped-in data file, which is denoted by the dot token `.`. The third argument of `assign` designates the destination environment `.GlobalEnv`.
```{r input, echo=48:49, eval=FALSE}
```
At this point it is useful to extract a key value used throughout downstream code: the number of age groups in the input data file. This value is assigned to `num_agestrat`. The desired value can be extracted from the `agestrat` column of the input data file, which is now named by the string `paste0(score_name, '_raw_by_agestrat')`. 

Once the data file is named by a concatenated string in this way, we must force R to evaluate the name not as a string, but as the name of an object in the global environment. We accomplish this by wrapping the file name in `eval(as.name())`. `base::as.name` coerces its argument to an object name. `base::eval` forces R to evaluate its argument, in this case returning an object name which can be processed by other functions. Appending this name with the suffix `$agestrat` specifies that we want to process a single column, not the entire table (`$` is a column-subsetting operator).

So identified, the target column contains values of `agestrat` for every case in the input data file. Wrapping the column name in `base::unique()` returns only the unique values of `agestrat` in the form of a numerical vector. Using `base::length()` we return the length of this vector (the number of values it contains), i.e., the number of age groups, which is the value we seek for `num_agestrat`.
```{r input, echo=50, eval=FALSE}
```

<br>

#### Examine input data, generate frequency tables by agestrat, descriptive statistics, z-score lookup table

###### VALID CODE TO RUN
```{r freq_desc, eval=FALSE}
eval(as.name(paste0(score_name, '_raw_by_agestrat'))) %>% count(!!as.name(score_name)) %>% 
  mutate(perc = round(100*(n/sum(n)), 4), cum_per = round(100*(cumsum(n)/sum(n)), 4), lag_raw = lag(!!as.name(score_name)), lag_cum_per = lag(cum_per)) %>% 
  assign(paste0(score_name, '_freq_agestrat'), ., envir = .GlobalEnv)

eval(as.name(paste0(score_name, '_raw_by_agestrat'))) %>% arrange(agestrat) %>% summarise(n = n(),
                                                                                          median = round(median(eval(as.name(score_name))), 2),
                                                                                          mean = round(mean(eval(as.name(score_name))), 2),
                                                                                          sd = round(sd(eval(as.name(score_name))), 2)) %>%
  mutate(ES = round((mean - lag(mean))/((sd + lag(sd))/2),2), group = c(1:num_agestrat)) %>% 
  assign(paste0(score_name, '_desc_agestrat'), ., envir = .GlobalEnv)

agestrat <- eval(as.name(paste0(score_name, '_desc_agestrat'))) %>% pull(agestrat)
max_mean <- max(eval(as.name(paste0(score_name, '_desc_agestrat')))$mean)
max_SD <- max(eval(as.name(paste0(score_name, '_desc_agestrat')))$sd)
scale_y_break_options <- seq(0, max_mean+(2*max_SD), 5)
scale_y_ceiling_mean <- scale_y_break_options[which.min(abs(scale_y_break_options - (max_mean+(2*max_SD))))]
scale_y_ceiling_SD <- scale_y_break_options[which.min(abs(scale_y_break_options - (max_SD+(max_SD/2))))]

# Create Z score table
perc_z <- tribble(
  ~lohi_value,	~z_score,
  5, 1.6449,
  10,	1.2816,
  15,	1.0364,
  20,	0.8416,
  25,	0.6745,
  75,	0.6745,
  80,	0.8416,
  85,	1.0364,
  90,	1.2816,
  95,	1.6449
)

write_csv(eval(as.name(paste0(score_name, '_desc_agestrat'))), here(
  paste0(
    'OUTPUT-FILES/DESCRIPTIVE-TABLES/',
    score_name,
    '-descriptives-agestrat-',
    format(Sys.Date(), "%Y-%m-%d"),
    '.csv'
  )
))

write_csv(eval(as.name(paste0(score_name, '_freq_agestrat'))), here(
  paste0(
    'OUTPUT-FILES/DESCRIPTIVE-TABLES/',
    score_name,
    '-frequencies-agestrat-',
    format(Sys.Date(), "%Y-%m-%d"),
    '.csv'
  )
))
```

###### COMMENTED CODE CHUNKS
This next code snippet generates a table of raw score frequencies by agestrat. The input data object is `eval(as.name(paste0(score_name, '_raw_by_agestrat')))`, which refers to the input normative data file read in by upstream code. `base::paste0()` concatenates `score_name` with a static suffix to create a string naming the data object. To coerce this string into an object name that R can evaluate, we wrap the string in `eval(as.name())` (both are `base` functions).

The object is then piped into `dplyr::count()`, which yields two columns: `score_name`, containing all values of the raw score being normed, and `n`, containing the number of cases per each raw score value. Because `count`, like all `dplyr` functions, quotes its inputs, and `score_name` is a character vector containing a string, we coerce `score_name` into an object name using `as.name`, and unquote it using the `!!` operator. The important distinction is that `score_name` *refers* to the object we want to process (a column name), but `dplyr::count` cannot evaluate `scorename` as the column name until we wrap `score_name` in `as.name` and `!!`. In R, a string referring to an object is *not* equivalent to the object's name - only the latter can be evaluated. 

(Note: these two methods of coercing R to evaluate strings as objects, `eval(as.name)`, and `!!as.name` are used throughout this script, but they will only be documented here.)

Next, the columns created by `count` are piped into `dplyr::mutate()`, which generates four more columns: `perc`, the percentage of total cases for each value of `score_name`; `cum_per`, the cumulative percentage over increasing values of `score_name`; and `lag_raw` and `lag_cum_per`, two `base::lag()` columns that provide the values for `score_name` and `cum_per` *from the previous row*. These columns are rounded `base::round()` to four decimal places. `assign` names the output frequency table and makes it available in the global environment.
```{r freq_desc, echo=1:3, eval=FALSE}
```
The next snippet generates a table of descriptive statistics by `agestrat`, named by `assign` with the suffix `_desc_agestrat`. The input normative data object is piped into `dplyr::arrange()`, to sort by agestrat. The data object was previously grouped by `agestrat`, which means that summary statistics can now be calculated for those groups. This is accomplished by piping the object into `dplyr::summarise()`, yielding a summary table of descriptive statistics with one row per `agestrat`. These statistics are the raw-score `mean`, `median`, `sd`, and `ES` (effect size) for each `agestrat`, all rounded to two decimal places.
```{r freq_desc, echo=4:10, eval=FALSE}
```
Next we create vectors and values that are used repeatedly throughout the rest of the script. We use `dplyr::pull()` to extract the values of `agestrat` from the table of descriptive statistics. `pull` extracts a column of a data frame as a vector. We use `base::max()` to extract the maximum values of `mean` and `sd` from the table of descriptive statistics; the `$` subsetting operator allows us to specify a column by name.

To specify `scale_y_break_options`, a numerical vector providing the scale for the y-axis in plots generated by downstream code, we use `base::seq`. This function generates a numerical sequence, using arguments for starting number (`0`), ending number (`max_mean+(2*max_SD)`), and interval (`5`).

The ceiling values, for the mean and SD along the y-axis of plots, are extracted from `scale_y_break_options`. This is done so that plots can be scaled appropriately for the differing possible score ranges of the raw score being normed. 

Taking `scale_y_ceiling_mean` as an example, the inner expression `abs(scale_y_break_options - (max_mean+(2*max_SD)))` is a vector that gives the absolute values of the differences between the values along `scale_y_break options` and the quantity `max_mean+(2*max_SD)`, the latter representing an estimate of the highest y-axis value needed to capture all points of the score or quantity being plotted. This inner expression is wrapped in `base::which.min()`, which returns the position (in the sequence of values in the vector), of the minimum value of the inner expression (i.e., the minimum height of the graph needed to plot all points). That minimum value is extracted from `scale_y_break_options` using the subsetting operator `[]` and assigned to the name `scale_y_ceiling_mean`.

```{r freq_desc, echo=12:17, eval=FALSE}
```
We use `tibble::tribble()` to generate a z-score lookup table, associating z-scores with normalized percentile points. `tribble` allows creating of a tibble using an inline method, laying out the data within the script in a readable columnar format, with column heads.
```{r freq_desc, echo=19:32, eval=FALSE}
```
The next snippet saves out two date-labeled tables, descriptive statistics by `agestrat` and frequency counts by `agestrat`, for the score being normed. These tables are written to .csv format using `readr::write_csv()`. The file path within `here::here()` is concatenated with `paste0()`, which joins static strings with the value contained in `score_name`, as well as with a dynamic current date value provided by `base::Sys.Date()`. The latter is wrapped in `base::format`, which takes `"%Y-%m-%d"` as its second argument, specifying that the date part of the file name will be written in ISO 8601 format.
```{r freq_desc, echo=34:52, eval=FALSE}
```

<br>

#### Plot raw score means, print descriptives table

###### VALID CODE TO RUN
```{r RSmean_plot, eval=FALSE}
mean_plot <- ggplot(data = eval(as.name(paste0(score_name, '_desc_agestrat'))), aes(group, mean)) +
  geom_point(
    col = "blue",
    fill = "blue",
    alpha = .5,
    size = 3,
    shape = 23
  ) +
  geom_label_repel(aes(label = mean), hjust = .7, vjust = -1, label.padding = unit(0.1, "lines"), size = 4, col = "blue") +
  scale_x_continuous(breaks = seq(1, num_agestrat, 1), labels = agestrat) +
  scale_y_continuous(breaks = seq(0, scale_y_ceiling_mean, 5), limits = c(0, scale_y_ceiling_mean)) +
  labs(title = "Raw Score Means (with SDs)", x = "Agestrat", y = "Total Score") +
  geom_errorbar(
    aes(ymin = mean - sd, ymax = mean + sd),
    col = "red",
    size = 0.2,
    width = 0.2
  ) 
print(mean_plot)
eval(as.name(paste0(score_name, '_desc_agestrat'))) %>% print(n = nrow(.))
```

###### COMMENTED CODE CHUNKS
`ggplot()` takes as input the table of descriptive statistics (named by `eval(as.name(paste0(score_name, '_desc_agestrat')))`), yielding a scatterplot `geom_point` that maps `group` (a proxy for `agestrat`) to the x-axis and raw score `mean` to the y-axis, using the argument `aes(group, mean)`. Plot output is assigned to `mean_plot` so that the plot will print when the code is executed from source. `col` controls the color of the plot point perimeter; `fill` controls the color of the point interior. You can adjust the values of these arguments to change the appearance of the graph. Other useful argments include `alpha` (controls transparency of data element, values 0-1), `size` (of data points), `shape` (designated by a number, which can be obtained from charts on the internet).
```{r RSmean_plot, echo=1:8, eval=FALSE}
```
`ggplot` builds out graphs one layer at a time. Additional layers are added using the `+` operator. The first layer on top of the basic scatterplot is given by `ggrepel::geom_label_repel()`. This applies labels to the mean points `aes(label = mean)`. 
These labels "repel" away from the points so that the numerical value of the mean is not sitting right on top of the corresponding plot point itself. The appearance of these labels, as well as their proximity to the plot points, is controlled by the arguments `hjust`, `vjust`, `label.padding`, `size`, and `col`.

The next layers are given by `scale_x_continuous` and `scale_y_continuous`, which apply new scales to the axes. `breaks = seq(1, num_agestrat, 1)` indicates that the axis will be segmented by units of 1, running from 1 to `num_agestrat` (the number of age groups in the input table). `labels = agestrat` replaces the numerical sequence on the axis with labels from the char vector `agestrat` (note: this vector must have length equal to `num_agestrat` for this code to work). `limits = c(0, scale_y_ceiling_mean)` sets lower and upper numerical limits on the y-axis, with the upper limit given by the value of `scale_y_ceiling_mean`, initialized in upstreatm code. `labs` specifies the title and super-ordinate labels for the axes.
```{r RSmean_plot, echo=9:12, eval=FALSE}
```
`geom_errorbar` allows you to layer error bars onto a plot. `aes()` is called to map separate variables onto the error bar below the data point `ymin` and the error bar above the data point `ymax`. In this case, SD bars are created by mapping `mean - sd` and `mean + sd`. In `geom_errorbar`, `size` controls the width of the tick at the top/bottom of the bar, and `width` controls the line thickness.
```{r RSmean_plot, echo=13:18, eval=FALSE}
```
An explicit `base::print()` call ensures that the plot will print to the viewer when the code is executed from source.
```{r RSmean_plot, echo=19, eval=FALSE}
```
The next snippet prints the table of descriptive statistics by `agestrat` to the console. This table is piped into `print(n = nrow(.))`, whose lone argument indicates that the data object should be printed in its entirety (that is, the number of printed rows `n` should be equal to the number of rows `nrow` in the piped-in object `.`.)
```{r RSmean_plot, echo=20, eval=FALSE}
```

<br>

#################start here###################

#### Pause execution for user to examine plot

When the code is sourced, the following chunk pauses execution and prompts the user to examine the newly created plot of raw score means and SDs.

###### VALID CODE TO RUN
```{r mean_plot_prompt, eval=FALSE}
mean_plot_prompt <- function() {
  writeLines(c(
    strrep("\u2500", 40),
    "Examine plot of raw score means and SDs.",
    "Then press [enter] to continue.",
    strrep("\u2500", 40)
  ))
  readline()
}
mean_plot_prompt ()
```
###### COMMENTED CODE CHUNKS
`mean_plot_prompt()` is a function that takes no arguments and thus can be called with empty parentheses.
```{r mean_plot_prompt, echo=1, eval=FALSE}
```
`writeLines` takes a character vector and prints it to the console, where each vector element is printed on a new line. `strrep("\u2500", 40)` repeats a unicode horizontal box drawing character `u2400` 40 times, thus enclosing the printed text between horizontal lines.
```{r mean_plot_prompt, echo=2:7, eval=FALSE}
```
`readline` pauses execution and waits for the user to press [enter], at which point execution resumes.
```{r mean_plot_prompt, echo=8, eval=FALSE}
```

<br>

#### Generate histograms by agestrat

###### VALID CODE TO RUN
```{r hist, eval=FALSE}
hist_plot <- ggplot(data = ANTraw_by_agestrat, aes(ANT_total)) +
  geom_histogram(
    binwidth = .2,
    col = "red"
  ) +
  scale_y_continuous(breaks = seq(0, 20, 1)) +
  labs(title = "Frequency Distribution") + 
  theme(panel.grid.minor=element_blank()) +
  facet_wrap(~agestrat)
print(hist_plot)
```
###### COMMENTED CODE CHUNKS
`ggplot` takes data frame `ANTraw_by_agestrat` as input, yielding histogram `geom_histogram` showing the distribution of variable `aes(ANT_total)`. Plot output is assigned to `hist_plot` so that plot will print when code is executed from source. `binwidth` controls width of histogram columns, `col` controls color of column outlines. Adjust the values of these arguments to change the appearance of the graph. 
```{r hist, echo=1:5, eval=FALSE}
```
`scale_y_continuous` applies new scale to y axis, using argument `breaks`. `seq` sets scale ranging from 0 to 20, in increments of 1. 
```{r hist, echo=6, eval=FALSE}
```
`labs` can be used to provide text labels for the graph, in this case a title.
```{r hist, echo=7, eval=FALSE}
```
`theme` changes non-data elements of graphic, in this case by removing minor gridlines. `element_blank` means 'draw nothing'.
```{r hist, echo=8, eval=FALSE}
```
`facet_wrap` generates separate histogram for each `agestrat`. 
```{r hist, echo=9, eval=FALSE}
```
Explicit `print` call ensures that plot will print when code is executed from source.
```{r hist, echo=10, eval=FALSE}
```
<br>

#### Generate graphs of means, SDs by agestrat.

###### VALID CODE TO RUN
```{r mean_SD_graph, eval=FALSE}
mean_plot <- ggplot(data = ANT_tot_desc_agestrat, aes(group, mean)) +
  geom_point(
    col = "blue",
    fill = "blue", 
    alpha = .5,
    size = 3,
    shape = 23
  ) +
  scale_x_continuous(breaks = seq(1, 27, 1), labels = agestrat) +
  scale_y_continuous(breaks = seq(0, 50, 5), limits = c(0, 50)) + 
  labs(title = "Means", x = "Agestrat", y = "Mean Total Score")
print(mean_plot)
  
sd_plot <- ggplot(data = ANT_tot_desc_agestrat, aes(group, sd)) +
  geom_point(
    col = "red",
    fill = "red", 
    alpha = .5,
    size = 3,
    shape = 23
  ) +
  scale_x_continuous(breaks = seq(1, 27, 1), labels = agestrat) +
  scale_y_continuous(breaks = seq(0, 10, 1), limits = c(0, 10)) + 
  labs(title = "SDs", x = "Agestrat", y = "SD Total Score")
print(sd_plot)
```

<br>

#### Generate table of lo1, lo2, hi1, hi2 cumulative percentage points by agestrat

This section of code takes as input the age-stratified frequency table of the raw score for which norms are being created. The assumptions are that the distribution of raw scores within each age group is skewed (non-normal), and that because of small sample sizes, the age-stratified means and SDs may vary considerably from one age group to the next, and thus may not fit the hypothesized developmental growth curve for the ability being measured. The overall purpose of this R script is to use the input data to model the underlying developmental curve, and then construct well-functioning norms based on that model. 'Well-functioning' in this context means no unexpected changes or reversals in the standard score corresponding to a particular raw score, as the individual being assessed ages from one normative age-group to the next.

The first step of this process is to normalize the raw score distributions within each age group. We begin by selecting five cumulative percentage (percentile) points: the median (`med`), and two points below below the median (`lo1`, `lo2`) and two above (`hi1`, `hi2`), with the latter four being as far out toward the tails of the distribution as possible. The possible values for the `lo` points are 5, 10, 15, 20, and 25, and the possible values for the `hi` points are 75, 80, 85, 90 and 95. 

Ideally, the values for `lo1`, `lo2`, `hi1` and `hi2` would be 5, 10, 90 and 95, respectively. But in order to use 5 as the value for `lo1`, there needs to exist a cumulative percentage in the frequency table that is less than 5. The reason for this is that the formula for imputing normalized raw scores uses values from two adjacent rows in the frequency table. Thus, the value for `lo1` cannot sit on the lowest row of the frequency table, because it needs a trailing row (lag row) in order for the imputation formula to run.

In many small sample size frequency tables, there exists no cumulative frequency value that is less than 5. For example the lowest value in the table might be 7.9, or 11.2. In these cases, the R code sets `lo1` at 10, or 15. The code automatically adjusts the values of `lo1`, `lo2` and `hi1` to ensure that the rows associated with these values always have a trailing row, and so that `lo2` sits on a different row than `lo1`, and `hi1` sits on a different row than `hi2`. In constrast to the other three points, `hi2` is a constant; its value is always set at 95. Because `hi2` sits at the top of the frequency distribution, it always has a trailing row and thus its value can be locked at the optimal value of 95.

`lo1`, `lo2`, `hi1` and `hi2` are used later used to impute raw scores that __WOULD__ be associated with each point, __IF__ the raw scores were normally distributed. The next section of code processes the age-stratified frequency table and chooses lo1, lo2, hi1, and hi2 for each age group.

###### VALID CODE TO RUN
```{r lo_hi_SD, eval=FALSE}
ANT_tot_age_lo1lo2_hi1hi2 <-
  full_join(
    ANT_tot_freq_agestrat,
    (
      ANT_tot_freq_agestrat %>%
        group_by(agestrat) %>%
        summarise(min = min(cum_per)) %>%
        mutate(lo1 = case_when(
          min < 5 ~ 5,
          min < 10 ~ 10,
          min < 15 ~ 15,
          min < 20 ~ 20,
          TRUE ~ 25
        ))
    ),
    by = 'agestrat'
  ) %>%
  group_by(agestrat) %>% mutate(flag = case_when(cum_per > lo1 &
                                                   cum_per < 95 ~ 1,
                                                 TRUE ~ 0)) %>% filter(flag == 1) %>% summarise(min = min(cum_per),
                                                                                                max = max(cum_per),
                                                                                                lo1 = first(lo1)) %>%
  mutate(
    lo2 = case_when(
      lo1 == 5 & min < 10 ~ 10,
      lo1 == 5 & min < 15 ~ 15,
      lo1 == 5 & min < 20 ~ 20,
      lo1 == 5 & min >= 20 ~ 25,
      lo1 == 10 & min < 15 ~ 15,
      lo1 == 10 & min < 20 ~ 20,
      lo1 == 10 & min >= 20 ~ 25,
      lo1 == 15 & min < 20 ~ 20,
      lo1 == 15 & min >= 20 ~ 25,
      TRUE ~ 25
    ),
    hi1 = case_when(max > 90 ~ 90,
                    max > 85 ~ 85,
                    max > 80 ~ 80,
                    TRUE ~ 75),
    hi2 = 95
  ) %>% select(-min,-max)
```

###### COMMENTED CODE CHUNKS
Initializes an output table `ANT_tot_age_lo1lo2_hi1hi2`. `full_join` is analogous to SPSS MATCH FILES, in that it combines the columns of two tables (adding variables, not cases) according to the values of an index variable `by`. `full_join` keeps all values and all rows of the two tables that it combines. The code chunk below identifies the LHS table used by `full_join` as `ANT_tot_freq_agestrat`, the age-stratified frequency table.
```{r lo_hi_SD, echo=1:3, eval=FALSE}
```
The next code chunk identifies the RHS table used by `full_join` as a transformed version of `ANT_tot_freq_agestrat`, the age-stratified frequency table. `ANT_tot_freq_agestrat` is piped `%>%` through a series of functions. First, the table is grouped by agestrat `group_by`. Then it is transformed into a summary table with one row per agestrat, and one variable `min`, which is the minimum value of cumulative percentage `cum_per` within each agestrat. Here `summarise` operates as a quasi-lookup function, finding the minimum value within a numerical vector. `mutate` adds a second column `lo1` to the summary table. `lo1` can take one of five values: 5, 10, 15, 20, or 25; it will take the lowest of these values that is still higher than the  minimum cumulative percentile for that agestrat.  

Thus, values of `lo1` are coded according to values of `min` (the former depends on the latter). `case_when` performs this conditional transformation in a more elegant, readable way than nested `ifelse` statements. `min < 5 ~ 5` states that when `min` is less than 5, `lo1` is coded 5, and so on. `TRUE` is equivalent to ELSE in this conditional logic.  

The last line of this code chunk completes the specification of `full_join`, stating that the LHS and RHS tables are joined `by` the index variable `agestrat`. The data object at this point has the same number of rows as the full frequency table `ANT_tot_freq_agestrat`. `full_join` applies (recycles) the values of the two new variables, `min` and `lo1`, of which there is one value per agestrat, to all cells within a given agestrat in the larger (taller, more rows) table, thus filling out the table completely with those values.
```{r lo_hi_SD, echo=4:17, eval=FALSE}
```
Next we pipe the current data object (a tall table with the same number of rows as `ANT_tot_freq_agestrat`) through a series of transformations that allow it to become the basis for calculating `lo2`. The table is regrouped by `agestrat`, to provide a basis for later collapsing it back into a table with one row per agestrat. `mutate` then adds a new variable `flag` that is coded conditionally by `case_when`, such that cases are flagged if their value on `cum_per` is greater than `lo1` and less than 95. This coding on flag allows the data object to be filtered in a way that simplifies the calculation of `lo2` in a later procedure.  

The object is piped through `filter`, which keeps only the flagged rows. `summarise` transforms the object again into a collapsed table with one row per agestrat, adding three variables: minimum value of `cum_per` per agestrat, maximum value of `cum_per` per agestrat, and first value of `lo1`. Because all values of `lo1` are identical within each agestrat, `first` is a convenient way of simply designating that value for `lo1` in the collapsed table.
```{r lo_hi_SD, echo=18:22, eval=FALSE}
```
The current data object is a table with 27 rows, one for each agestrat. The next code chunk uses `mutate` to code `lo2` (possible values: 10, 15, 20, 25), `hi1` (possible values: 75, 80, 85, 90), and `hi2` (static value: 95). The conditional coding depends on varibles (`min`, `max`) that summarise the distribution of `cum_per` within each agestrat. Thus, R doesn't need to access the distributions in the original age-stratified frequency table `ANT_tot_freq_agestrat` to determine the correct values for `lo2` and `hi1`.
```{r lo_hi_SD, echo=23:40, eval=FALSE}
```
The line of code below cleans up the current object `ANT_tot_age_lo1lo2_hi1hi2` for use in the next procedure. `select` drops the named columns preceded by `-` (minus sign). Without the minus sign, `select` would have kept only the named columns.
```{r lo_hi_SD, echo=41, eval=FALSE}
```

<br>

#### Generate imputed medians, lo and hi SDs by agestrat

The process of normalizing each age-group raw score distribution continues, by adding columns for the imputed median, and standard deviations above and below the median (lo_SD, hi_SD). Dividing the standard deviation into two components contributes to normalization by compensating for the skewness in the original raw score distributions.

###### VALID CODE TO RUN
```{r med_SD_ES, eval=FALSE}
norm_build1 <-
  ANT_tot_freq_agestrat %>% left_join(ANT_tot_age_lo1lo2_hi1hi2, by = 'agestrat') %>% mutate (
    IRS_lo1 = ((lo1 - lag_cum_per) / perc) * (ANT_total - lag_raw) + lag_raw,
    IRS_lo2 = ((lo2 - lag_cum_per) /
                 perc) * (ANT_total - lag_raw) + lag_raw,
    IRS_med = ((50 - lag_cum_per) /
                 perc) * (ANT_total - lag_raw) + lag_raw,
    IRS_hi1 = ((hi1 - lag_cum_per) /
                 perc) * (ANT_total - lag_raw) + lag_raw,
    IRS_hi2 = ((hi2 - lag_cum_per) /
                 perc) * (ANT_total - lag_raw) + lag_raw,
    dist_point = case_when(
      lo1 <= cum_per & lo1 > lag_cum_per ~ 'lo1',
      lo2 <= cum_per &
        lo2 > lag_cum_per ~ 'lo2',
      50 <= cum_per &
        50 > lag_cum_per ~ 'med',
      hi1 <= cum_per &
        hi1 > lag_cum_per ~ 'hi1',
      hi2 <= cum_per &
        hi2 > lag_cum_per ~ 'hi2',
      TRUE ~ NA_character_
    )
  ) %>% drop_na() %>% mutate(IRS = case_when(dist_point == 'lo1' ~ IRS_lo1,
                                                             dist_point == 'lo2' ~ IRS_lo2,
                                                             dist_point == 'med' ~ IRS_med,
                                                             dist_point == 'hi1' ~ IRS_hi1,
                                                             dist_point == 'hi2' ~ IRS_hi2,
                                                             TRUE ~ NA_real_),
                                             RSD = case_when(dist_point == 'lo1' ~ lead(lead(IRS))-IRS,
                                                             dist_point == 'lo2' ~ lead(IRS)-IRS,
                                                             dist_point == 'med' ~ IRS,
                                                             dist_point == 'hi1' ~ IRS-lag(IRS),
                                                             dist_point == 'hi2' ~ IRS-lag(lag(IRS)),
                                                             TRUE ~ NA_real_),
                                             lohi_value = case_when(dist_point == 'lo1' ~ lo1,
                                                             dist_point == 'lo2' ~ lo2,
                                                             dist_point == 'hi1' ~ hi1,
                                                             dist_point == 'hi2' ~ hi2,
                                                             TRUE ~ 50)) %>% 
  select(agestrat, lo1, lo2, hi1, hi2, dist_point, lohi_value, IRS, RSD) %>% left_join(perc_z, by = 'lohi_value') %>% 
  mutate(std_RSD = RSD/z_score, SD = case_when(dist_point == 'lo1' | dist_point == 'hi1' ~ (std_RSD+lead(std_RSD))/2,
                                                                                            TRUE ~ NA_real_),
         median = case_when(dist_point == 'med' ~ IRS,
                            TRUE ~ NA_real_),
         lo_SD = case_when(dist_point == 'lo1' ~ SD,
                           TRUE ~ NA_real_),
         hi_SD = case_when(dist_point == 'hi1' ~ SD,
                           TRUE ~ NA_real_))
    
norm_build_med_hilo_sum <-
  norm_build1 %>% summarise(
    lo1 = first(lo1),
    lo2 = first(lo2),
    hi1 = first(hi1),
    hi2 = first(hi2),
    median = first(na.omit(median)),
    lo_SD = first(na.omit(lo_SD)),
    hi_SD = first(na.omit(hi_SD))
  ) %>% mutate(ES = (median - lag(median))/((hi_SD+lag(hi_SD)+lo_SD+lag(lo_SD))/4), group = 1:27) %>% select(group, everything())
```

###### COMMENTED CODE CHUNKS
Initializes an output table `norm_build1`. Input table is the age-stratified raw score frequency table `ANT_tot_freq_agestrat`. `left_join` matches the input table to the `lo1`, `lo2`, `hi1` and `hi2` normalizing cumulative percentage points for each `agestrat`. `mutate` computes new variables.
```{r med_SD_ES, echo=1:2, eval=FALSE}
```
The first set of new variables created by `mutuate` are the imputed raw scores `IRS_` for the median `med`, `lo1`, `lo2`, `hi1` and `hi2`. The `IRS_` formula includes the raw score `ANT_total` associated with `lo1`, `lo2`, `hi1` or `hi2`, along with the percentage of cases `perc` in that same row. The formula also incorporates the raw score `lag_raw` and cumulative percentage `lag_cum_tot` from the _trailing_ row. `mutate` calculates these values for every row, by `agestrat` even though eventually only the value in the row of `lo1` (for example) will flow through to the next set of calculations.
```{r med_SD_ES, echo=3:11, eval=FALSE}
```
Next `mutate` creates `dist_point` column. This column locates the rows in the table containing values of `cum_per` corresponding to the chosen values for `med`, `lo1`, `lo2`, `hi1` and `hi2`, and applies a label to flag these rows. In the flagged rows, the `lo1` label (for example) identifies the row where the value of `lo1` is less than or equal to the value of `cum_per` in that row, and greater than the value of `cum_per` in the trailing row. `case_when` is used to specify the logical conditions that identify the rows where the labels in `dist_point` are to be applied. The reason for flagging specific rows in this context is that we want to extract specific cells from columns (e.g., the `IRS_` columns) where a value is calculated for every row. We want to filter and pass only the rows corresponding to the `dist_point` labels to later operations.

Note the use of `TRUE ~ NA_character_` as the final argument of `case_when`. `TRUE` specifies the _ELSE_ condition in the `case_when` logic. When using `case_when` for conditional transformations, all RHS must evaluate to the same type of vector. In this instance, we want `TRUE` to evaluate to missing (`NA`), but this is a logical type, whereas the other RHS in this `case_when` are all character. `NA_character_` supports missing values in a character vector.
```{r med_SD_ES, echo=12:23, eval=FALSE}
```
Now the filtering operation: `drop_na()` drops any row that has `NA` in any column. In this instance, it drops all non-flagged rows in `dist_point`, resulting in a pared down table that includes, for each `agestrat`, only the five rows labeled `med`, `lo1`, `lo2`, `hi1` and `hi2`.

`mutate` creates new columns to be conditionally coded by `case_when`. `IRS` collapses the five `IRS_` columns into a single imputed raw score column, by plucking, for each row, the value in the `IRS_` column corresponding to that row's `dist_point`. For example, `case_when` sets the value of `IRS` to `IRS_lo1` when `dist_point` equals `lo1`, thus ignoring the other four `IRS_` columns. 

`RSD` calculates the difference between the imputed raw score for the `lo` and `hi` distribution points, and the imputed raw score for the `med` distibution point. It does this by operating on the `IRS` column, using `lag` and `lead` operators to perform arithmetic on values from trailing and leading rows, and nesting these operators when the target value is two rows away from the current row. 

`lohi_value` associates a numerical percentile value with each `dist_point` label, by collapsing the `lo1`, `lo2`, `hi1` and `hi2` columns into a single column, plucking the target values in a similar manner to the `IRS` calculation described above. In this instance, the `TRUE` argument of `case_when` is used to set the `med` percentile to 50.
```{r med_SD_ES, echo=24:40, eval=FALSE}
```
In the next snippet, `select` subsets columns into only the ones needed going forward. `left_join` looks up normalized z-scores `z_score` associated with the values of `lo1`, `lo2`, `hi1` and `hi2`, using the key variable `by = 'lohi_value'`.

`mutate` creates new columns. `std_RSD` standardizes `RSD` by dividing it by `z_score`.

`SD` estimates the standard deviation separately, above and below the median. It does this by averaging the standardized raw-score difference from the median `std_RSD`, across `lo1` and `lo2`, and separately across `hi1` and `hi2`. The calculation formula uses the `lead` operator to average adjacent cellls in the `std_RSD` column, and uses `case_when` to place the calculated values in the cells associated with `lo1` and `hi1`, setting all other cells in the `SD` column to `NA` (using `TRUE ~ NA_real_`).

`mutate` then creates the columns needed for the final summary table. `median` plucks the imputed median `IRS` associated with `dist_point` `med`, `lo_SD` plucks `SD` associated with `dist_point` `lo1` (the estimated SD _below_ the median), and `hi_SD` plucks `SD` associated with `dist_point` `hi1` (the estimated SD _above_ the median). The values are placed in the same row as the `dist_point` in all three columns, with all other cells set to `NA`.
```{r med_SD_ES, echo=41:49, eval=FALSE}
```
The final snippet creates the summary table `norm_build_med_hilo_sum` used in the next stage of the norming process. `summarise` takes the current data object `norm_build1` (already grouped by `agestrat`) as its input, outputting a summary table with 27 rows (one for each `agestrat`). The new summary columns are all built on columns from `norm_build1` that have only a single value per `agestrat`, meaning that the required value for the summary column can be plucked using the `first` operator.

The challenge with `median`, `lo_SD`, and `hi_SD` is that the single required value is embedded among multiple `NA`. To prevent `first` from plucking `NA`, it is wrapped around `na.omit`, which causes `first` to ignore `NA` until it finds a numerical value.

Finally, mutate adds an effect size column `ES` to the summary table, which gives the effect size of the difference between medians from one `agestrat` to the next. It then adds an ordinal `group` column and moves that to left-most position with `select` and the helper function `everything()`, i.e., specifying the column position of `group` relative to all other columns in the table.
```{r med_SD_ES, echo=51:60, eval=FALSE}
```

<br>

#### Use linear modeling to estimate "smoothed" medians, lo_SDs, and hi_SDs.

The imputed means and SDs retain the fluctuating variability between age-groups that was present in the original raw-score distributions. The next step is to smooth out this variability by fitting regression lines to the scatter plots for age vs. med, age vs. lo_SD, and age vs. hi_SD, and using the regression coefficients from these lines to generate "smoothed" medians, lo_SDs and hi_SDs for each age group. These smoothed values become the basis for the norms moving forward.

To generate the smoothed median for each age group, you choose between a 1st, 2nd, or 3rd-order polynomial equation as the smoothing forumula. The code generates fitted plots for each of these models, showing the regression coefficients and R^2^ for each, allowing you to choose the appropriate model. The 3rd-order polynomial usually provides the best fit. You can also inspect the plots for the 2nd- and 1st-order polynomials, to determine if a reasonably good fit can be achieved with a more parsimonius model. 

For the lo_SDs and hi SDs, the code produces plots of the 1st-order (straight line) model and the mean substitution (horizontal line) model. Again, you select the model by examining the plots and judging which model best fits the data.

Model selection is done via an interactive session. The console lists the model choices and prompts you to examine the plots and make a selection, successively for median, lo_SD, and hi_SD. In order for this interactive feature to work, the entire script must be executed from source, using `command-shift-S`.

###### VALID CODE TO RUN
```{r plot_model_med, eval=FALSE}
rm(ANT_tot_age_lo1lo2_hi1hi2, ANTraw_by_agestrat, norm_build1)

frm <- c('y ~ x', 'y ~ x + I(x^2)', 'y ~ x + I(x^2) + I(x^3)')
title <-
  c('1st order polynomial',
    '2nd order polynomial',
    '3rd order polynomial')
lo_hi <- c('lo_SD', 'hi_SD')

med_plots <- map2(
  title,
  frm,
  ~
    ggplot(norm_build_med_hilo_sum, aes(x = group, y = median)) +
    geom_point(
      col = 'red',
      fill = 'red',
      alpha = .5,
      size = 3,
      shape = 23
    ) +
    labs(
      x = 'age group'
      ,
      y = 'median'
      ,
      title = paste0('Median: ', .x)
    ) +
    scale_x_continuous(breaks = seq(1, 27, 1), labels = agestrat) +
    scale_y_continuous(breaks = seq(0, 50, 5)) +
    geom_smooth(
      method = 'lm',
      se = FALSE,
      formula = .y
    ) +
    stat_poly_eq(
      formula = .y,
      eq.with.lhs = 'italic(hat(y))~`=`~',
      aes(label = paste(..eq.label.., ..rr.label.., sep = '*plain(\',\')~')),
      parse = TRUE
    )
)
print(med_plots)

model_median_1st <- function() {
  lm(median ~ group, data = norm_build_med_hilo_sum) %>% assign('model_median', ., envir = .GlobalEnv)
  get_regression_points(model_median, digits = 6) %>% pull(median_hat) %>% assign('median_sm', ., envir = .GlobalEnv)
}

model_median_2nd <- function() {
  lm(median ~ group + I(group ^ 2), data = norm_build_med_hilo_sum) %>% assign('model_median', ., envir = .GlobalEnv)
  get_regression_points(model_median, digits = 6) %>% pull(median_hat) %>% assign('median_sm', ., envir = .GlobalEnv)
}

model_median_3rd <- function() {
  lm(median ~ group + I(group ^ 2) + I(group ^ 3), data = norm_build_med_hilo_sum) %>% assign('model_median', ., envir = .GlobalEnv)
  get_regression_points(model_median, digits = 6) %>% pull(median_hat) %>% assign('median_sm', ., envir = .GlobalEnv)
}

model_prompt_median <- function() {
  writeLines(
    "Examine plots and choose smoothing model for medians:\n\n1: First-order polynomial: y = ax + b\n2: Second-order polynomial: y= ax^2 + bx + c\n3: Third-order polynomial: y= ax^3 + bx^2 + cx + d\n"
  )
  model_choice <- as.numeric(0)
  while (is.na(model_choice) || (!(model_choice %in% 1:3))) {
    model_choice <-
      suppressWarnings(as.numeric(readline(prompt = "Enter choice: ")))
    if (is.na(model_choice)) {
      writeLines("Please enter 1, 2, or 3\n")
    } else {
      if (model_choice == 1) {
        model_median_1st()
        break
      } else if (model_choice == 2) {
        model_median_2nd()
        break
      } else if (model_choice == 3) {
        model_median_3rd()
        break
      } else {
        writeLines("Please enter 1, 2, or 3\n")
      }
    }
  }
}
model_prompt_median()
```

<br>

#### Plot imputed medians with fitted regression lines

###### COMMENTED CODE CHUNKS
Clean up environment by dropping superfluous tables.
```{r plot_model_med, echo=1, eval=FALSE}
```
Define char vectors containing formulas, plot labels. Note the formula format used for the 2nd- and 3rd-order polynomials in `frm`. The 2nd- and 3rd-order terms `x^2` and `x^3` are wrapped in `I()`. This forces R to evaluate `^` as as an _arithmetic_ operator (instead of as a _formula_ operator), and thus the polynomial expression is evaluated correctly. 

As an aside, R has another format for higher-order polynomial formulas `poly()`, (e.g., `poly(x, 3)` to express a 3rd-order polynomial). `poly()` doesn't work in the current application, because it produces an orthoganol polynomial solution, which doesn't lead to usable predicted values when used to model the smoothed medians.
```{r plot_model_med, echo=3:8, eval=FALSE}
```
Use `purrr::map2` to iterate over two parallel vectors of equal length. In this case, `map2` renders three scatterplots of the imputed median, by iterating over `title` (containing plot titles) and `frm` (containing regression line formulas), substituting elements of those vectors as arguments in a `ggplot` call. Note that this sets up _parallel_ iteration, where corresponding elements are drawn from both input vectors at each iteration, as opposed to _nested_ iteration, which iterates through all elements of a subordinate vector at (for) each element of a superordinate vector. 

In the `map2` call, the first two arguments are the input vectors `title` and `frm`. These are followed by `~`, a shorthand for designating an anonymous function. The iteration tokens `.x` and `.y` appear in the body of the function at the places where `map2` substitutes elements of the input vectors, with `.x` functioning as a placeholder for elements of the first input vector `title`, and `.y` functioning as a placeholder for the elements of the second input vector `frm`.

Note that the plots rendered by `map2` are assigned to the object `med_plots`, so that the plots will print when the code is sourced.
```{r plot_model_med, echo=10:13, eval=FALSE}
```
`ggplot` takes as input the table of imputed medians, lo_SD, hi_SD `norm_build_med_hilo_sum`. It generates a scatterplot `geom_point` of age group on the x-axis and median on the y-axis `aes(x = group, y = median)`. (Note: some lines/arguments of the `ggplot` call were documented earlier in this Notebook, and will not be repeated here.)
```{r plot_model_med, echo=14:15, eval=FALSE}
```
Substitution for `.x` from the `title` vector takes place in the following line of code, which uses `paste0` to concatenate string elements to create a `title` for each of the three plots.
```{r plot_model_med, echo=27, eval=FALSE}
```
`ggplot2` allows the creation of layered plots. In the current instance, `geom_point()` created the base layer of a scatterplot, `labs` added a layer of labels, and now `geom_smooth()` will be used to layer on a regression line. (`+` is used to add an additional layer). `method` specifies the smoothing or modeling approach (in this case `lm` for linear model). `se = FALSE` indicates that no error bars will be shown on the regression line. `formula = .y` designates the regression equation to be used; here `.y` is a placeholder for the polynomial formulas contained in `frm`, which will be substituted as `map2` iterates.
```{r plot_model_med, echo=31:35, eval=FALSE}
```
The final layer is specified by `ggpmisc::stat_poly_eq` which prints the corresponding regression equation and fit statistic on each plot, yielding three complete plots that can be used to compare the fits of 1st-, 2nd- and 3rd-order polynomial models. `map2` subtitutes the model formulas for `.y` in `formula = .y`. `eq.with.lhs` designates the string that prints to form the LHS of the regression equation. `aes` creates a `label` that prints to serve as the RHS of the regression equation: `paste` creates the `label` string by concatenating two string elements: the equation for the fitted polynomial `..eq.label..`, and the R^2^ for the fitted polynomial `..rr.label..` (`sep` designates the sequence of characters used to separate these two elements within the parsed string). `parse = TRUE` converts the label text into an expression (which R can perform actions on).
```{r plot_model_med, echo=36:41, eval=FALSE}
```
Explicit `print` command ensures that plots will print when code is executed from source.
```{r plot_model_med, echo=43, eval=FALSE}
```

<br>

#### Generate smoothed (estimated) medians for three linear models

As noted in the previous section, the norming process continues with the choice of models to smooth out the inter-age group variability in the imputed medians. In the smoothing process, `group` is used to predict (estimate) the smoothed values for the imputed medians. The regression coefficients from the selected linear model are used to generate the smoothed values for each age group. `group` is used as a linear, equal-interval proxy for the ordinal sequence of `agestrat` labels. Somewhat counterintuitively, the imputed values of median are _not_ used to estimate the smoothed values of those same variables. Using `group` as the independent variable in the linear models provides the desired smoothed values.

###### COMMENTED CODE CHUNKS
The script contains three named functions (`model_median_1st`, `model_median_2nd`, `model_median_3rd`) that return vectors holding estimated (smoothed) medians for the 1st-, 2nd-, and 3rd-order polynomial formulas. Because the three functions are analogous, only the 3rd-order function is documented in detail.

`model_median_3rd` is a function whose body contains two operations. The first operation is the estimation of the linear model using `lm`. The first argument of `lm` specifies the terms of the 3rd-order polynomial formula, in which `group` is used to predict `median`. The second argument of `lm`, `data =`, specifies that the input values for model estimation are taken from the summary table `norm_build_med_hilo_sum` created by upstream code. The output of `lm` is piped into `assign`, whose first argument specifies a named object `model_median` to hold the model ouput. The second argument of `assign`,  `.`, specifies that the piped input will be assigned to `model_median`, and the third argument `envir = .GlobalEnv` specifies that `model_median` will be available in the global environment, where it can be processed in downstream functions.

The second operation of `model_median_3rd` creates a numerical vector `median_sm` that holds the smoothed (predicted) median values across the levels of `agestrat`. `moderndive::get_regression_points` extracts the regression coefficients from `model_median` and uses them to generate the smooted medians. The output of `get_regression_points` is a tibble in which one column `median_hat` contains the smoothed medians. This output is piped through `dplyr::pull` which extracts the medians column, which is assigned to `median_sm`.

```{r plot_model_med, echo=55:58, eval=FALSE}
```

<br>

#### Use interactive session to select median smoothing model

Previous code plotted imputed medians vs. agestrats, and fit 1st-, 2nd-, and 3rd-order polynomial regression lines to the imputed medians. This code also created functions that generate the estimated (smoothed) medians associated with each of these models. 

When sourced, the script generates the plots and prompts you to examine the plots and enter a choice for smoothing model at the console. The next set of snippets encodes a function that lists the model choices on the console and prompts you to select a model by entering its number. The smoothed medians associated with the selected model are thereby incorporated in all downstream code.

This interactive session can only be executed from source by entering `command-shift-S`. The code cannot be run as an isolated block using `command-enter`; this mode of execution won't pause and wait for user input.

###### COMMENTED CODE CHUNKS
The function that enables this interactive session is designated `model_prompt_median`. `writeLines` prints user instructions for model selection to the console as a numbered list, using the escape character `\n` to insert line breaks in the printed text.
```{r plot_model_med, echo=60:63, eval=FALSE}
```
`model_choice` is initialized as a numeric vector with placeholder value of 0. Within the function `model_prompt_median`, `model_choice` will hold the numerical value that the user enters when prompted by the console instructions. The value of `model_choice` controls the flow of logic within `model_prompt_median`; its value determines which of the three smoothed median estimation functions will be executed. Note that the assignment operator `<-` is used to initialize `model_choice`, rather than the `assign` function that was used in the bodies of the smoothed median estimation functions. The reason for this is that `model_choice` is a temporary variable that is not utilized outside of the body of this particular function. Thus, it does not need to be made available in the global environment. When `<-` is used within the body of a function, the object thereby created is avaiable _only_ in the local environment of that function. In this instance, we can get away with using `<-` because `model_choice` is not needed in the global environment.
```{r plot_model_med, echo=64, eval=FALSE}
```
The selected smoothed median estimation function is called and executed within a `while` loop, which iterates as long as a compound logical condition is met (logical "or" `||`). This condition is specified by `is.na(model_choice) || (!(model_choice %in% 1:3)`, which tells the `while` loop to keep iterating as long as the value of `model_choice` is anything other than 1, 2, or 3 (i.e., the user enters a non-permitted value at the console). Thus, if the user enters an integer other than 1, 2, or 3, or any other keystroke(s), including `enter` without an entry, the loop will continue to iterate and control will _not_ be passed to downstream code. `is.na(model_choice)` is included in this compound condition because any keystroke other than 1, 2, or 3 is coerced to `NA` within this function. Thus, the loop keeps iterating if the function returns `NA`.
```{r plot_model_med, echo=65, eval=FALSE}
```
Within the `while` loop, `model_choice` is respecified to read user input from the console. `readline` allows the specification of a prompt at the console, and reads user input, which is then assigned to `model_choice`. Wrapping `readline` in `suppressWarnings` keeps the printed text on the console clean and readable.
```{r plot_model_med, echo=66:67, eval=FALSE}
```
`if`-`else` statements control the flow of operations within the loop. The first `if` statement specifies that if `model_choice` is `NA` (i.e., the user enters a non-permitted keystroke(s) at the console), `writeLines` prints a reminder to enter a permitted keystroke, and then control returns to the beginning of the loop, where `readline` again prompts the user to enter a model choice.
```{r plot_model_med, echo=68:69, eval=FALSE}
```
Next comes a nested logical flow that is subsumed under `else`. When control enters the nested flow, the logical condition is that `model_choice` is _not_ `NA`. The nested `if`-`else` statements control what happens when the user enters a permitted choice (i.e., the value of `model_choice` is 1, 2, or 3). Under each of these three conditions (specified by sequential `if`-`else if`-`else if` commands), the smoothed median function associated with a particular value of `model_choice` is called, followed by `break` which causes control to exit the loop and continue into downstream code. Thus, the `model_median_prompt` function prompts the user to select a model at the console, repeats the prompt when a non-permitted choice is entered, and ultimately executes one of three smoothed median estimation functions and makes the output of that function available to downstream code.
```{r plot_model_med, echo=70:79, eval=FALSE}
```
A final `else` condition is triggered by any user input not subsumed under the prior logical conditions. It reprompts the user, and returns control to the beginning of the loop. As noted above, the loop will only stop running if the user enters 1, 2, or 3.
```{r plot_model_med, echo=80:81, eval=FALSE}
```
`model_prompt_median` is called with empty parentheses `()` because it takes no arguments. The function simply executes the code within its body, it does not depend on any input values specified in the function call.
```{r plot_model_med, echo=86, eval=FALSE}
```

<br>

#### Estimate smoothed lo_SDs, hi_SDs

The code for estimating smoothed values for the lo_SDs and hi_SDs is analogous to that detailed above for the smoothed medians. The operations flow from plotting the imputed values with lines for 1st-order polynomial and mean-subsitution smoothing models, to initializing functions that will smooth the SDs based on these two models, to using an interactive session to select the smoothing models for the SDs. This process is completed first for the lo_SDs, and then for the hi_SDs. This section of code concludes by generating the summary table that is used in downstream norming processes, and removing unneeded objects from the global environment.

The code is only documented in detail where it differs from previous code.

###### VALID CODE TO RUN
```{r plot_model_SDs, eval=FALSE}
lo_SD_1st_plot <-
  ggplot(norm_build_med_hilo_sum, aes(x = group, y = lo_SD)) +
  geom_point(
    col = 'red',
    fill = 'red',
    alpha = .5,
    size = 3,
    shape = 23
  ) +
  labs(x = 'age group'
       ,
       y = "lo_SD"
       ,
       title = 'lo_SD 1st order polynomial') +
  scale_x_continuous(breaks = seq(1, 27, 1), labels = agestrat) +
  scale_y_continuous(breaks = seq(0, 10, 1)) +
  geom_smooth(method = 'lm',
              se = FALSE,
              formula = y ~ x) +
  stat_poly_eq(
    formula = y ~ x,
    eq.with.lhs = 'italic(hat(y))~`=`~',
    aes(label = paste(..eq.label.., ..rr.label.., sep = '*plain(\',\')~')),
    parse = TRUE
  )

mean_lo_SD <- round(mean(norm_build_med_hilo_sum$lo_SD), 2)
lo_SD_mean_plot <-
  ggplot(norm_build_med_hilo_sum, aes(x = group, y = lo_SD)) +
  geom_point(
    col = 'red',
    fill = 'red',
    alpha = .5,
    size = 3,
    shape = 23
  ) +
  labs(x = 'age group'
       ,
       y = 'lo_SD'
       ,
       title = 'lo_SD mean substitution') +
  scale_x_continuous(breaks = seq(1, 27, 1), labels = agestrat) +
  scale_y_continuous(breaks = seq(0, 10, 1)) +
  geom_hline(yintercept = mean_lo_SD) +
  geom_label(aes(5, mean_lo_SD, label = paste0("Mean lo_SD = ", mean_lo_SD)))

print(lo_SD_1st_plot)
print(lo_SD_mean_plot)

model_lo_SD_1st <- function() {
  lm(lo_SD ~ group, data = norm_build_med_hilo_sum) %>% assign('model_lo_SD', ., envir = .GlobalEnv)
  get_regression_points(model_lo_SD, digits = 6) %>% pull(lo_SD_hat) %>% assign('lo_SD_sm', ., envir = .GlobalEnv)
}

model_lo_SD_mean <- function() {
  norm_build_med_hilo_sum %>% mutate(mean_lo_SD = mean_lo_SD) %>% pull(mean_lo_SD) %>% assign('lo_SD_sm', ., envir = .GlobalEnv)
  enframe(mean(norm_build_med_hilo_sum$lo_SD), name = NULL, value = "model_lo_SD") %>% assign('model_lo_SD', ., envir = .GlobalEnv)
}

model_prompt_lo_SD <- function() {
  writeLines(
    "\nExamine plots and choose smoothing model for lo_SDs:\n\n1: First-order polynomial: y = ax + b\n2: Mean substitution: y= mean(x)\n"
  )
  model_choice <- as.numeric(0)
  while (is.na(model_choice) || (!(model_choice %in% 1:2))) {
    model_choice <-
      suppressWarnings(as.numeric(readline(prompt = "Enter choice: ")))
    if (is.na(model_choice)) {
      writeLines("Please enter 1 or 2\n")
    } else {
      if (model_choice == 1) {
        model_lo_SD_1st()
        break
      } else if (model_choice == 2) {
        model_lo_SD_mean()
        break
      } else {
        writeLines("Please enter 1 or 2\n")
      }
    }
  }
}
model_prompt_lo_SD()

hi_SD_1st_plot <-
  ggplot(norm_build_med_hilo_sum, aes(x = group, y = hi_SD)) +
  geom_point(
    col = 'red',
    fill = 'red',
    alpha = .5,
    size = 3,
    shape = 23
  ) +
  labs(x = 'age group'
       ,
       y = "hi_SD"
       ,
       title = 'hi_SD 1st order polynomial') +
  scale_x_continuous(breaks = seq(1, 27, 1), labels = agestrat) +
  scale_y_continuous(breaks = seq(0, 10, 1)) +
  geom_smooth(method = 'lm',
              se = FALSE,
              formula = y ~ x) +
  stat_poly_eq(
    formula = y ~ x,
    eq.with.lhs = 'italic(hat(y))~`=`~',
    aes(label = paste(..eq.label.., ..rr.label.., sep = '*plain(\',\')~')),
    parse = TRUE
  )

mean_hi_SD <- round(mean(norm_build_med_hilo_sum$hi_SD), 2)
hi_SD_mean_plot <-
  ggplot(norm_build_med_hilo_sum, aes(x = group, y = hi_SD)) +
  geom_point(
    col = 'red',
    fill = 'red',
    alpha = .5,
    size = 3,
    shape = 23
  ) +
  labs(x = 'age group'
       ,
       y = 'hi_SD'
       ,
       title = 'hi_SD mean substitution') +
  scale_x_continuous(breaks = seq(1, 27, 1), labels = agestrat) +
  scale_y_continuous(breaks = seq(0, 10, 1)) +
  geom_hline(yintercept = mean_hi_SD) +
  geom_label(aes(5, mean_hi_SD, label = paste0("Mean hi_SD = ", mean_hi_SD)))

print(hi_SD_1st_plot)
print(hi_SD_mean_plot)

model_hi_SD_1st <- function() {
  lm(hi_SD ~ group, data = norm_build_med_hilo_sum) %>% assign('model_hi_SD', ., envir = .GlobalEnv)
  get_regression_points(model_hi_SD, digits = 6) %>% pull(hi_SD_hat) %>% assign('hi_SD_sm', ., envir = .GlobalEnv)
}

model_hi_SD_mean <- function() {
  norm_build_med_hilo_sum %>% mutate(mean_hi_SD = mean_hi_SD) %>% pull(mean_hi_SD) %>% assign('hi_SD_sm', ., envir = .GlobalEnv)
  enframe(mean(norm_build_med_hilo_sum$hi_SD), name = NULL, value = "model_hi_SD") %>% assign('model_hi_SD', ., envir = .GlobalEnv)
}

model_prompt_hi_SD <- function() {
  writeLines(
    "\nExamine plots and choose smoothing model for hi_SDs:\n\n1: First-order polynomial: y = ax + b\n2: Mean substitution: y= mean(x)\n"
  )
  model_choice <- as.numeric(0)
  while (is.na(model_choice) || (!(model_choice %in% 1:2))) {
    model_choice <-
      suppressWarnings(as.numeric(readline(prompt = "Enter choice: ")))
    if (is.na(model_choice)) {
      writeLines("Please enter 1 or 2\n")
    } else {
      if (model_choice == 1) {
        model_hi_SD_1st()
        break
      } else if (model_choice == 2) {
        model_hi_SD_mean()
        break
      } else {
        writeLines("Please enter 1 or 2\n")
      }
    }
  }
}
model_prompt_hi_SD()

smooth_med_SD <-
  cbind(norm_build_med_hilo_sum, median_sm, lo_SD_sm, hi_SD_sm) %>% dplyr::select(-(lo1:hi2)) %>%
  mutate(ES_sm = round((median_sm - lag(median_sm)) / ((
    lo_SD_sm + lag(lo_SD_sm) + hi_SD_sm + lag(hi_SD_sm)
  ) / 4), 3))

rm(list = ls()[!ls() %in% c("smooth_med_SD", "model_median", "model_lo_SD", "model_hi_SD")])
```







###### COMMENTED CODE CHUNKS

The mean-subsitution model smooths the SDs by substituting their mean for every imputed value. The lo_SD mean is generated by the following code (taking the mean of the column of imputed lo_SD values, specified by `norm_build_med_hilo_sum$lo_SD`). The value is assigned to `mean_lo_SD`, a numerical vector of length 1.
```{r plot_model_SDs, echo=27, eval=FALSE}
```

The next two lines are part of the `ggplot` call to add a horizontal line to the mean-substitution plot. That line is layered on by `geom_hline`, which draws a horizontal line at the value of `mean_lo_SD` using the `yintercept` argument. `geom_label` applies a label to the line with the value of the mean (the first argument of `aes`, 5, refers to the position of the label relative to the line).
```{r plot_model_SDs, echo=44:45, eval=FALSE}
```

The next snippet addresses the fact that the output of model choice for lo_SD (and hi_SD) can be either a linear model or a constant (mean of SDs). Downstream code needs either type of output to be in an object named `model_lo_SD`. `enframe` puts the constant into a 1x1 tibble, `name = NULL` gets rid of an unneeded column, and `value` controls the name of the one remaining column. Downstream, a logical gate controls the code applied to `model_lo_SD`, depending on whether that object contains the linear model or the tibble.
```{r plot_model_SDs, echo=55:59, eval=FALSE}
```

The next snippet creates the output table `smooth_med_SD` used in the next stage of the norming process. `base::cbind` joins columns of equal length into a data frame, in this case joining the input table `norm_build_med_hilo_sum` to the new columns of smoothed values: `median_sm`, `lo_SD_sm`, and `hi_SD_sm`. This combined table is piped through `dplyr::select` to remove unneeded columns, and then through `dplyr::mutate`, to create a colmn of effect sizes for the smoothed medians. In the effect size formula, note the use of `lag` to bring in values from the preceeding row.

```{r plot_model_SDs, echo=169:173, eval=FALSE}
```


